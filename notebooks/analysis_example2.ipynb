{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a43d7c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded market rows: 380, option rows: 380, window: ('2015-01-29', '2016-07-13')\n"
     ]
    }
   ],
   "source": [
    "# ---- Offline, deterministic market + option loader (no network, no project imports) ----\n",
    "from pathlib import Path\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "START, END = \"2015-01-01\", \"2025-01-01\"\n",
    "RISK_FREE_RATE = 0.02\n",
    "VOL_WINDOW = 20\n",
    "\n",
    "# Deterministic RNG for any synthetic generation\n",
    "_DEFAULT_RNG = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "def _read_csv_flexible(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV and parse first column as timestamp index, robust to 'Unnamed: 0' or named columns.\"\"\"\n",
    "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
    "    df.index.name = \"timestamp\"\n",
    "    return df.sort_index()\n",
    "\n",
    "\n",
    "def _load_from_dataset_cards(prefer_split: str = \"train\"):\n",
    "    \"\"\"Read market/option from the newest runs/*/dataset_card.json entry with rows > 0.\n",
    "    Returns (market_df, option_df, (start, end)) or (None, None, None).\n",
    "    \"\"\"\n",
    "    runs_dir = Path(\"runs\")\n",
    "    cards = sorted(runs_dir.glob(\"*/dataset_card.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    for cp in cards:\n",
    "        try:\n",
    "            entries = json.loads(cp.read_text())\n",
    "        except Exception:\n",
    "            continue\n",
    "        windows = {}\n",
    "        for e in entries:\n",
    "            if e.get(\"split\") != prefer_split or e.get(\"rows\", 0) <= 0:\n",
    "                continue\n",
    "            win = (e.get(\"start\"), e.get(\"end\"))\n",
    "            windows.setdefault(win, {})[e.get(\"kind\")] = e.get(\"file\")\n",
    "        for (ws, we), kinds in sorted(windows.items()):\n",
    "            if \"market\" in kinds:\n",
    "                m = _read_csv_flexible(kinds[\"market\"]) if kinds.get(\"market\") else None\n",
    "                o = _read_csv_flexible(kinds[\"option\"]) if kinds.get(\"option\") else None\n",
    "                if m is not None and not m.empty:\n",
    "                    return m, o, (ws, we)\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def _find_runs_csv_pair():\n",
    "    \"\"\"Heuristic: scan runs/* for '*market*.csv' and corresponding '*option*.csv' in the same folder.\n",
    "    Robust to malformed CSVs (skips on read errors).\n",
    "    \"\"\"\n",
    "    runs_dir = Path(\"runs\")\n",
    "    if not runs_dir.exists():\n",
    "        return None, None, None\n",
    "    run_dirs = sorted([p for p in runs_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    for rd in run_dirs:\n",
    "        market_files = sorted([p for p in rd.glob(\"*.csv\") if \"market\" in p.name])\n",
    "        option_files = sorted([p for p in rd.glob(\"*.csv\") if \"option\" in p.name])\n",
    "        if market_files:\n",
    "            try:\n",
    "                m = _read_csv_flexible(str(market_files[0]))\n",
    "            except Exception:\n",
    "                continue\n",
    "            o = None\n",
    "            if option_files:\n",
    "                try:\n",
    "                    o = _read_csv_flexible(str(option_files[0]))\n",
    "                except Exception:\n",
    "                    o = None\n",
    "            if m is not None and not m.empty:\n",
    "                win = (str(m.index.min().date()), str(m.index.max().date()))\n",
    "                return m, o, win\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def _gbm_synthetic(n_days: int = 300, seed: int = 42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mu, sigma = 0.08, 0.15\n",
    "    dt = 1.0 / 252.0\n",
    "    r = rng.normal(mu * dt, sigma * math.sqrt(dt), size=n_days)\n",
    "    prices = 100.0 * np.exp(np.cumsum(r))\n",
    "    idx = pd.date_range(START, periods=n_days, freq=\"B\")\n",
    "    df = pd.DataFrame({\n",
    "        \"Open\": prices,\n",
    "        \"High\": prices * (1 + np.abs(rng.normal(0, 0.001, n_days))),\n",
    "        \"Low\": prices * (1 - np.abs(rng.normal(0, 0.001, n_days))),\n",
    "        \"Close\": prices,\n",
    "        \"Volume\": rng.integers(1_000_000, 10_000_000, n_days),\n",
    "    }, index=idx)\n",
    "    # Returns and annualized daily vol\n",
    "    df[\"Returns\"] = df[\"Close\"].pct_change()\n",
    "    df[\"Volatility\"] = df[\"Returns\"].rolling(VOL_WINDOW).std() * math.sqrt(252)\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "# Minimal Blackâ€“Scholes pricer (no SciPy dependency)\n",
    "_DEF_EPS = 1e-12\n",
    "\n",
    "\n",
    "def _norm_pdf(x: np.ndarray) -> np.ndarray:\n",
    "    return (1.0 / math.sqrt(2.0 * math.pi)) * np.exp(-0.5 * np.asarray(x) ** 2)\n",
    "\n",
    "\n",
    "def _norm_cdf(x: np.ndarray) -> np.ndarray:\n",
    "    # Use math.erf applied elementwise to avoid SciPy\n",
    "    x_arr = np.asarray(x, dtype=float)\n",
    "    erf_vec = np.vectorize(math.erf)\n",
    "    return 0.5 * (1.0 + erf_vec(x_arr / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def _bs_price_delta(S: np.ndarray, K: float, T: float, sigma: np.ndarray, r: float = RISK_FREE_RATE):\n",
    "    S = np.asarray(S, dtype=float)\n",
    "    sigma = np.asarray(sigma, dtype=float)\n",
    "    T = float(T)\n",
    "    # Guardrails\n",
    "    sigma = np.maximum(sigma, 1e-6)\n",
    "    S = np.maximum(S, _DEF_EPS)\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    call_price = S * _norm_cdf(d1) - K * math.exp(-r * T) * _norm_cdf(d2)\n",
    "    call_delta = _norm_cdf(d1)\n",
    "    return call_price, call_delta\n",
    "\n",
    "\n",
    "def _compute_option_df(market_df: pd.DataFrame, strike_price: float = None, T: float = 1.0 / 252.0) -> pd.DataFrame:\n",
    "    \"\"\"Compute call option price/delta per timestamp from market_df using rolling vol.\"\"\"\n",
    "    if strike_price is None:\n",
    "        strike_price = float(market_df[\"Close\"].iloc[0])\n",
    "    sigma = market_df[\"Volatility\"].fillna(market_df[\"Volatility\"].median()).to_numpy()\n",
    "    S = market_df[\"Close\"].to_numpy()\n",
    "    prices, deltas = _bs_price_delta(S, strike_price, T, sigma, r=RISK_FREE_RATE)\n",
    "    option_df = pd.DataFrame({\n",
    "        \"option_price\": prices,\n",
    "        \"delta\": deltas,\n",
    "        \"volatility\": sigma,\n",
    "        \"strike\": strike_price,\n",
    "    }, index=market_df.index)\n",
    "    return option_df\n",
    "\n",
    "\n",
    "# Load priority: dataset_card.json -> runs/* CSVs -> synthetic GBM\n",
    "market, option, window = _load_from_dataset_cards(prefer_split=\"train\")\n",
    "if market is None:\n",
    "    m2, o2, win2 = _find_runs_csv_pair()\n",
    "    market, option, window = m2, o2, win2\n",
    "\n",
    "if market is None:\n",
    "    market = _gbm_synthetic(n_days=400, seed=42)\n",
    "    window = (str(market.index.min().date()), str(market.index.max().date()))\n",
    "\n",
    "# Ensure returns/vol present (if loaded from CSVs that lacked them)\n",
    "if \"Returns\" not in market.columns:\n",
    "    market[\"Returns\"] = market[\"Close\"].pct_change()\n",
    "if \"Volatility\" not in market.columns:\n",
    "    market[\"Volatility\"] = market[\"Returns\"].rolling(VOL_WINDOW).std() * math.sqrt(252)\n",
    "market = market.dropna()\n",
    "\n",
    "# Ensure we have option data; if missing or misaligned, compute locally\n",
    "if option is None or option.empty or not market.index.equals(option.index):\n",
    "    option = _compute_option_df(market)\n",
    "\n",
    "print(f\"Loaded market rows: {len(market):,}, option rows: {len(option):,}, window: {window}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae80e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded window and align frames; avoid project configs\n",
    "start, end = window\n",
    "m = market.loc[str(start):str(end)]\n",
    "o = option.loc[m.index]\n",
    "\n",
    "# Guard against emptiness early (episode_length=60)\n",
    "EP_LEN = 60\n",
    "min_len = EP_LEN + 1\n",
    "if len(m) < min_len or len(o) < min_len:\n",
    "    raise RuntimeError(f\"Not enough rows in the selected window ({len(m)}). Need at least {min_len}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eea03fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode steps: 60, CVaR95: -1436.485928, total PnL: 4721.723563\n"
     ]
    }
   ],
   "source": [
    "# Self-contained offline hedging harness: simulate delta hedging and compute PnL + CVaR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters matching env defaults\n",
    "EP_LEN = 60\n",
    "POSITION_SCALE = 1000\n",
    "TC_BPS = 1.0  # 0.0001 fraction -> 1 bps; we'll allow explicit bps here\n",
    "\n",
    "\n",
    "def simulate_delta_hedge(m: pd.DataFrame, o: pd.DataFrame, episode_length: int = EP_LEN,\n",
    "                          position_scale: float = POSITION_SCALE, tc_bps: float = TC_BPS,\n",
    "                          seed: int = 42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    assert len(m) == len(o)\n",
    "    n = len(m)\n",
    "    # Single continuous episode over the window\n",
    "    hedge_position = 0.0\n",
    "    portfolio_value = 0.0\n",
    "    pnl_steps = []\n",
    "    for t in range(min(n - 1, episode_length)):\n",
    "        current_price = float(m.iloc[t][\"Close\"]) \n",
    "        next_price = float(m.iloc[t + 1][\"Close\"]) \n",
    "        current_option = o.iloc[t]\n",
    "        next_option = o.iloc[t + 1]\n",
    "\n",
    "        option_pnl = float(next_option[\"option_price\"] - current_option[\"option_price\"]) \n",
    "        # Hedge target equals -delta (simple delta hedger)\n",
    "        target_position = -float(current_option[\"delta\"]) * float(position_scale)\n",
    "        position_change = target_position - hedge_position\n",
    "        tc_rate = float(tc_bps) / 10000.0\n",
    "        transaction_costs = abs(position_change) * current_price * tc_rate\n",
    "        hedge_pnl = -hedge_position * (next_price - current_price)\n",
    "\n",
    "        total_pnl = option_pnl + hedge_pnl - transaction_costs\n",
    "        pnl_steps.append(total_pnl)\n",
    "\n",
    "        portfolio_value += total_pnl\n",
    "        hedge_position = target_position\n",
    "\n",
    "    return np.array(pnl_steps)\n",
    "\n",
    "\n",
    "# CVaR utility (left tail, losses negative)\n",
    "def cvar(values, alpha: float = 0.95):\n",
    "    arr = np.asarray(values, dtype=float)\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "    k = max(1, int(np.floor((1.0 - alpha) * arr.size)))\n",
    "    tail = np.sort(arr)[:k]\n",
    "    return float(tail.mean())\n",
    "\n",
    "\n",
    "episode_pnl = simulate_delta_hedge(m, o, episode_length=EP_LEN, position_scale=POSITION_SCALE, tc_bps=TC_BPS)\n",
    "\n",
    "cvar_95 = cvar(episode_pnl, 0.95)\n",
    "print(f\"Episode steps: {len(episode_pnl)}, CVaR95: {cvar_95:.6f}, total PnL: {episode_pnl.sum():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d60ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PnL and summary to runs/offline_demo\n"
     ]
    }
   ],
   "source": [
    "# Optional: save arrays to runs/ for reproducibility (no network)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "out_dir = Path(\"runs\") / \"offline_demo\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.save(out_dir / \"episode_pnl.npy\", episode_pnl)\n",
    "with open(out_dir / \"summary.txt\", \"w\") as f:\n",
    "    f.write(f\"window={window}\\nrows={len(m)}\\nsteps={len(episode_pnl)}\\ncvar95={cvar_95}\\n\")\n",
    "print(f\"Saved PnL and summary to {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60065995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using offline harness above. This cell is disabled.\n"
     ]
    }
   ],
   "source": [
    "# Disabled: project imports and network-bound data are not used in offline mode.\n",
    "print(\"Using offline harness above. This cell is disabled.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
